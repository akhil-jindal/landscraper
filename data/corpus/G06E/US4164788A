Super-resolution imaging system 
US-4164788-A
Atul Jain
1979-08-14
https://patents.google.com/patent/US4164788A/en
ORIGIN OF INVENTION
The invention described herein was made in the performance of work under a NASA contract and is subject to the provisions of Section 305 of the National Aeronautics and Space Act of 1958, Public law 85-568 (72 Stat. 435, 42 USC 2457).
BACKGROUND OF THE INVENTION
This invention relates to imaging systems, and more particularly to a method and apparatus for greatly improving the resolution of an imaging system.
High resolution for imaging systems is a problem due to the fact that the high frequency detail of the object diffracts the incident illumination to angles much greater than what the collecting aperture can gather. Because of that a considerable amount of information is lost in most imaging systems. Therefore, the finite size of the primary collector presents a fundamental limitation on the resolving power of any practical imaging system. Since the cost and the practical difficulties involved with building large aperture imaging systems increases with the size of this aperture, it has in the past been of great interest to find alternative means of obtaining a higher resolution with a small aperture. Since the case of an infinitely small collecting aperture is equivalent to the case of not having any imaging components, imaging or scanning of an object in such a case is also of great interest.
SUMMARY OF THE INVENTION
In a preferred embodiment of the invention, an object is radiated off axis (with or without a lens system) by a plane wave field from a coherent source at an angle, Î¸, and the wave field, or intensity, of the wave field transmitted (or reflected) by the object is detected at some point in the image plane of the object while the spatial phase relationship of the radiating wave field is varied, either by varying the frequency, the angle or the distance of the object from the source. The wave field (amplitude and phase) or intensity (amplitude) detected is processed as a function of the variable to obtain the Fourier transform of the wave field to provide an enhanced image of the object itself along a line in the plane of the illuminating angle. Assuming that the angle, Î¸, is in the X-Z plane, where the Z axis is in the direction to the object, the image thus produced is along the X axis. The position of the object relative to the imaging system can be moved in a direction normal to the plane of the angle, i.e, in the Y axis direction, and the process repeated for each new position to obtain a two dimensional image. In some applications it is easier, or perhaps only possible, to detect just the intensity of the wave field. Since the intensity is simply the absolute square of the wave field, the Fourier transform of the intensity with respect to the variable is the autocorrelation of the image wave field. Thus, while the Fourier transform of the intensity does not directly provide the super-resolution amplitude and phase structure of the imaged object, the autocorrelation function provides sufficient information to warrant direct measurement of intensity.
A description of the preferred embodiments will emphasize the case of a coherent light source, a fixed illumination angle, Î¸, and a variable frequency, but it should be understood that the coherent source may be, for example, a source of ultrasonic waves, and that the frequency may be held constant while varying the angle. With off axis illumination in the X direction, the Fourier transform of the wave field with respect to the frequency (inverse wavelength) at a far field region point of an image plane yields an image of the object in the X dimension with a resolution factor related to the span of the frequency variation. Similarly, with a fixed wavelength and a variable angle of illumination, the Fourier transform of the wave field detected with respect to the angle of incidence yields an image of the object in the dimension of the angle variation with a resolution factor related to the span of the angle variation possible. When it is possible to use a combination of both angular and wavelength variation, one angle in the plane of one axis is set to be very large (e.g., Î¸x =30Â°) while another angle in the plane of another orthogonal axis is varied over a small range (e.g., Î¸y Â±ÎÎ¸y). At the same time the frequency of coherent source is varied. A two-dimensionsl Fourier transform with respect to the frequency and angle variations yields an image of the object in two dimensions with a resolution factor related to the bandwidth of angular and frequency variation. It is also possible to use a combination of the angle variation in the two directions Î¸x, Î¸y to provide a two-dimensional image. Another possibility is to vary the distance to the object along the Z axis instead of varying the frequency.
As used herein, the term "wave field" refers to both the amplitude and phase of the waves radiating from the source. In the case of electromagnetic radiation, such as for example radar, X-ray, or light as in the preferred embodiment to be described, the term "electric field" is equivalent to the generic term "wave field," and refers to both the phase and intensity of the radiation. The generic term wave field is intended to apply to other forms of coherent wave propagation, such as ultrasonic waves, for example.
BRIEF DESCRIPTION OF THE DRAWINGS
FIG. 1 is a block diagram of a system implemented to carry out the present invention in different modes of operation.
FIG. 2 is a diagram useful in understanding the principles of the invention.
DESCRIPTION OF PREFERRED EMBODIMENTS
Referring now to the drawings, FIG. 1 illustrates the organization of a general, or universal, system for imaging an object 10 (with an optional lens L1) onto a plane 11. The system is universal in that it provides a coherent source of radiation 12, such as a laser, of tunable wavelength under the control of a unit 13, and deflectors 14 and 15, such as rotatable prisms or electro-optic effect devices, for deflecting the illuminating beam in the respective X-Z and Y-Z planes under control of a unit 16. The Z axis is the axis of the beam in the direction of the object and the X axis is assumed to be in the plane of the drawings. The Y axis is then perpendicular to the plane of the paper. Imaging with super-resolution is thus possbile with either a variable radiation wavelength (frequency) or a variable angle of incidence of the radiation transmitted through the object 10, or with both a variable wavelength and angle, in which case one of the deflectors is set at a large angle (e.g., 30Â°) while the other is varied over a small angle of about 1Â°.
An optional Z-position translator 17 is also provided to effectively phase modulate light transmitted through the object by varying the position of the object along the Z axis instead of varying the wavelength of the source 12. Modulation by varying the position of the object in the Z plane is fully equivalent to varying the angle or the wavelength at normal incidence, as may be better appreciated by reference to the diagram of FIG. 2 which shows the incident coherent light transmitted through the object 10 at an angle Î¸x to the image plane 11 without the optional lens. FIG. 2 may also be used to better understand that when the direction of the incident light is normal to the object, the transmitted light must then be detected at the image plane off axis for super resolution.
The electric field at an image point P for the object 10 is the electric field transmitted (or reflected) by the object over the area of the corresponding resolution cell (determined by the resolving power of the imaging system) multiplied by the impulse response of the imaging system and integrated over this area. However, the electric field exiting the object depends upon the wavelength and angle of incidence as well as the phase (height in the Z axis) and amplitude (length in the X axis) structure of the object. Thus the value of the electric field at the image plane 11 varies with the wavelength or angle or incidence on the object.
Since moving the object (or the source) along the Z axis will vary the phase relationships of the incident light as detected at an off axis, far-field point, as can be seen from the diagram of FIG. 2, the value of the electric field at the image point varies with the position of the object along the Z axis. Consequently, the Fourier transform of this variation provides directly the amplitude and phase structure of the object within the resolution cell corresponding to the image point of interest.
It will, in most cases, be more convenient to vary the wavelength (represented by the space between wavefronts in FIG. 2) so that it is only necessary to set the deflectors 14 and 15, one for the desired offset angle of incidence (e.g., Î¸x), and the other to zero, or to set the wavelength of the source and vary the angle of incidence. Consequently, the Z position translator 17 can be omitted, as well as one of the angle deflectors 14 and 15, except for two dimensional imaging, in which case both deflectors are required. However, it is desirable to be able to move the object in order to image different areas. An X-Y position translator 18 is provided for that purpose.
It is also convenient to detect the electric field at different points in the image plane 11. An X-Y position translator 19 is provided to move a detector 20 in the image plane. All position translators provide a Fourier transform processor 21 with signals which uniquely identify the positions of the object 10 and detector 20, as well as the values of the variables, namely wavelength, and angles Î¸x and Î¸y in order for the Fourier transform to be computed by the processor 21, squared by a squarer 22, and the result displayed as an image in a unit 23 and/or recorded in a unit 24. Position data is recorded to provide stereo viewing of the object.
Since any variations in the intensity of the radiation source will result in variations in the electric field measurements made through the detector 20, it is necessary to maintain the intensity of the radiation substantially constant. That can be done by sampling the radiation using a beam splitter 25 and a detector 26 to provide a feedback signal to a differential amplifier 27 to so maintain the intensity of the radiation source that the difference between the feedback signal and a constant reference signal (voltage) is maintained at or very near zero. However, it is preferable to omit the detector 26 and differential amplifier 27, and to merely sample the radiation just in front of the object using a beam splitter 28 and a detector 29. The intensity of the radiation thus measured is then used in the Fourier transform processor 21 to normalize the measurements made through the detector 20. Any variation is intensity caused by the deflectors 14 and 15 will thus be compensated. However, it may be advantageous to provide both feedback control of the source and compensation in the processor.
With or without feedback control of the source, it is desirable to employ the beam splitter 25 to sample the radiation and transmit the sampled radiation to the detector 20 for heterodyne detection; alternatively an independent local oscillator synchronized with the light source for heterodyne detection. A beam splitter 30 may be employed to combine the sampled radiation with radiation from the object. Reflectors 31 and 32 direct the sampled radiation to the beam splitter 30. In the case of feedback control, the reflector 31 would be a beam splitter.
Before describing the operation of the system of FIG. 1 in different modes, the Fourier transform carried out in the processor 21 for high-resolution imaging will be described. Consider the geometry of FIG. 2 without a lens. A plane wave of a given wavelength is incident on the subject 10 at angles Î¸x, Î¸y with respect to the direction to the object (Z axis). The amplitude transmittance of the object is assumed to be a(x,y) and the transmitted radiation is detected at some point P in the far field region or the image plane of the object. Assuming a unit amplitude illumination, and using scalar diffraction theory in the following calculations, consider only the case of linear polarization.
The electric field, Eo, at the output plane of the object 10 is given by, ##EQU1## where h(x,y) is the surface phase transmittance profile of the object, and where the time dependent eiÏt term has been suppressed for monochromatic illumination.
In the super-resolution imaging of an object, three possible arrangements are of interest. When an imaging system of pupil aperture function P(x,y) is used and the impulse response is Î¨(x,y), the image electric field is (for unit magnification) ##EQU2## z=the distance of the limiting aperture P(x,y) from the image, and * the convolution operation.
For the case when the Fresnel zone electric field scattered by the object is detected at distance z from the object, we have ##EQU3##
When the Fraunhofer field is detected at distance z from the object, ##EQU4##
When the field is detected at a single point, the Fraunhofer case is equivalent to the case when the image pupil function P(x,y) is a delta function and the imaging system has an infinitely poor resolution. The Fresnel case is equivalent to the Fraunhofer case except for the fact that the point at which the field is detected is so close to the object that the quadratic phase factors across the object become important. In the sub-resolution imaging, these quadratic phase factors only contribute to a stretching of the image and their effect on the actual imaging process can be ignored. Thus only the sub-resolution imaging case for the Fraunhofer field will be considered and the equivalent calculations for the imaging case or the Fresnel field case can be made correspondingly. Since the system is spatially symmetric, interchanging (Î¸x, x) with (Î¸y,y) does not change the essential results. Thus in calculations where Î¸y =o, the corresponding effect for Î¸x =o, Î¸y Â±o can be easily determined. Also for most surfaces, the effect of h(x,y) is considered equal to zero and will only contribute a small random background noise which may be ignored.
Substituting Equation (1) into Equation (2c), the result is ##EQU5## For the particular point P, at (0,0) on the plane II, Equation (3) reduces to ##EQU6## Now evaluate the Fourier transform of EF (0,0) with respect to the wavenumber k. In general, the tunability for the wavelength of the illumination is over some certain region of Îk wavenumbers band-width and at some center frequency fo which has the corresponding wavenumber ko. Thus, in evaluating the Fourier transform of EF (0,0) as in (4), take into account this limited bandwidth available. This Fourier transform may, therefore, be written as ##EQU7## where Î³x is the image coordinate in the x dimension and EF (0,0) has been producted by rect [(k-Ko)/Îk] to take into account the limited bandwidth available around the wavenumber ko. Substituting (4) into (5), obtain the result ##EQU8## First evaluate Equation (6) with respect to k. Since the limits of the intergration have been set over the region ko Â±Îk/2 by the rect [(k-ko)/Îk] in the integral, and since the phase term ##EQU9## is varying at a much greater rate than the 1/Î» term, the variation in the 1/Î» term is ignored in evaluating the integral over k. This gives the result ##EQU10## where sinc (x) is defined as sinÏx/Ïx.
Note that Equation (7) is in the form of a convolution and can be written explicitly as ##EQU11## Equation (8) expresses the Fourier transform of the electric field with respect to the wavenumber in the far field region of an object and shows that it is the electric field transmitted by the object convolved with a resolution factor related to the bandwidth of the frequency variation available. The width of this resolution factor in the x-dimension is 2Ï/Îk sin Î¸x where Î¸x is the angle of illumination employed. If the wavelength span of 1000 A is employed, the illumination angle taken to be 60Â°, and the center wavelength taken to be 5000 A, we obtain the resolution cell size in the x dimension as 2.9 Î¼m. In the y-dimension the resolution is very poor, since the image electric field is the integrated field exiting the object plane over the y-axis.
It is possible to proceed to perform a similar calculation for the Fourier transform of the field detected at P with respect to the angle of illumination when the wavelength of illumination is not varied but the incident angle Î¸x is changed by the span ÎÎ¸x around Î¸xo. The pupil function describing this angular bandwidth employed is assumed to be rect [(sin Î¸x -sin Î¸xo)/Î(sin Î¸x)] where Î(sin Î¸x)/2â sin (Î¸x +ÎÎ¸x /2)-sin Î¸x. The Fourier transform of EF (0,0) is defined, using the same notation used in Equation (6) as follows ##EQU12## Substituting Equation (4) into Equation (9), evaluating, and simplifying the result, the function eF (o,o,Ïx) is found to be given by the convolution ##EQU13## The Fourier transform of the electric field detected at point P with respect to the angle of incidence is thus obtained as the convolution of the electric field exiting the object plane I with the function {(eikz/iÎ»z)e-i2Ï(x/Î») sin Î¸.sbsp.xo.sup.(Î Sin Î¸.sbsp.x) sinc [Î(sin Î¸x)x/Î»]} which has the width given by Î»/Î(sin Î¸x). Thus, the resolution of the image obtained in this fashion, for an angular width of Â±5Â° centered around normal incidence, and for an incidence wavelength of 5000 A, is 2.9 Î¼m in the x-dimension. Again, the resolution in the y-dimension is very poor since the field is integrated over the whole y-axis.
It is possible to obtain a high resolution in both dimensions by using a combination of both wavelength and angular variation monitoring. Consider the case when the illumination angle in the direction of the x axis is Î¸x, and the angle that the y component of the k vector for the illumination makes with the normal to the object is Î¸y, and assume that Î¸x >>Î¸y. In computing the Fourier transform of the electric field with respect to the variation in the wavelength of the illumination and in the angle Î¸y, the electric field exiting plane I is given by

 E.sub.o (x,y)=a(x,y)e.sup.ikx sin Î¸.sbsp.x.sup.+iky sin Î¸.sbsp.y,                                           (11)
and the corresponding electric field detected at point P is written as ##EQU14## Recording the value of EF (0,0) while the incident wavevector is varied from ko -Îk/2 to ko +Îk/2 and the angle of incidence in the y direction from -ÎÎ¸y /2 to +ÎÎ¸y /2. yields the function EF (0,0) rect [(k-ko)/Îk] rect [sin Î¸y /Î(sin Î¸y)].
Now taking the two-dimensional transform of this function as defined by ##EQU15## and substituting Equation (12) into Equation (13) the following equation is obtained: ##EQU16## Evaluating Equation (14) over only the k variable, neglecting the 1/Î» variation compared to the phase term over the region ko Â±Îk, yields ##EQU17## Since it is assumed that Î¸yo =0, and that the variation of Î¸y is so small that ÎÎ¸y <<Î¸x, it is possible to ignore y sin Î¸y compared to the x sin Î¸x term. The sinc [Îk/2Ï(Î³x -x sin Î¸x -y sin Î¸y -z)] can be approximated by sinc [Îk/2Ï(Î³x -x sin Î¸x -z)]. Using this approximation to evaluate Equation (15) yields ##EQU18## which can be rewritten as the convolution ##EQU19## Thus, provided Î¸y +ÎÎ¸y <<Î¸x, the resulting two-dimensional Fourier transform with respect to the wavenumber k and the angle of illumination variation Î¸y, would give the electric field transmitted by the object 10 convolved with the impulse response factors for the x and y dimensions, the widths of which are 1/Îk sin Î¸x and Î»/Î(sin Î¸y) in the x and y dimensions respectively. Thus, as in previous considerations, for Î»=5000 A, ÎÎ»=1000 A, Î¸x =60Â°, Î¸y =0Â°Â±5Â° this would correspond to a resolution of 2.9 Î¼m in the x and y dimensions respectively. Consider now the scanning application where high resolution is obtained in one dimension and the object translated with respect to the illumination in the other direction. In order to do this, assume that the illumination spot on the object is given by the function rect (x/2Lx) rect (y-Î±/2Ly ) which is a rectangle of width 2Lx, 2Ly in the x and y dimensions respectively and centered at (0, Î±). While the wavelength or angular variation is used to obtain the high resolution along the x dimension the object is translated with respect to the illumination in the y direction, i.e., Î± is varied. For any particular value of Î±, use (7) to provide the Fourier transform with respect to the wavenumber of the electric field detected at the point P. This is given by, for the object transmittance now given by ##EQU20## Differentiating (18) with respect to Î± and rearranging terms, we have the result, ##EQU21## From Equation (19) it is evident that, provided a(x,y) is known for the region 0<y<2Ly, the function a(x,y) may be determined from Equation (21) for all values of y for any given Ly. Thus, for scanning applications, while high resolution may be obtained in one dimension by varying the wavelength or angle of illumination, the other dimension may be resolved if the object is translated with respect to this axis and if the object transmittance is known in the initial spot size region.
The electric field at the point (Î²,0) also depends upon the distance z of the detector plane from the object. Evaluating the integral ##EQU22## for zo a mean distance, EF (Î²,0) as defined in Equation (3) and Î¸x =0, Î²/z>>1 ##EQU23##
While Equations (3) to (20) have been evaluated with the assumption that the spatial effect of the object phase transmittance h(x,y) is zero, consider now the case when Î¸x =Î¸y =0, h(x,y)Â±0, and the integral (5) is evaluated. The result is ##EQU24## For Îk large, eF (Î³x) has non-zero values only for Î³=2h. This point may be clarified further by assuming that there is only one phase scatterer on the object and the function h(x) is described by h(x)=ho rect(x-xo)/wo where (xo,o) is the position of this scatterer of height ho and width wo.
The function eF (Î³x) will have a non-negligible value only at Î³=2ho and the magnitude of this value will be ##EQU25## For a multitude of scatterers of height hr, width wr on the object, the function eF (Î³x) will be a series of peaks at Î³x =2hr and the heights of these peaks will be equal to ##EQU26## For a continuous function describing h(x) the function eF (Î³x) will be some continuous function for various values of Î³x depending on the fraction of the total function that has the height equal to Î³x produced by the values of a(x,y) at those particular Î³=2h. By placing a mask, with step function heights of equal widths and different values placed at different spatial points, in contact with the object a(x,y), the values of a(x,y) can be sampled by measuring the Fourier transform of the electric field detected versus wavelength and noting that the position of the peaks on this transform correspond to the heights on the phase mask and the value of these peaks to the value of a(x,y) at the corresponding points on the mask.
While Equations (8), (10), (17) and (19) have been calculated for the case when point P is at (0,0), it is interesting to note the effect of making the imaging measurement at some point other than the origin. To illustrate, consider the derivation of Equations (7) and (10) using the values xo =-Î² and yo =0 in (3). Proceeding with similar steps leading from Equations (3) to (8), it is found that the Fourier transform with respect to the wavenumber of the field detected at (-Î²,0) is given by ##EQU27## Similarly the equivalent of Equation (10) becomes ##EQU28##
Note from Equation (22) that detecting the wavelength dependent electric field at a point other than the origin simply shifts the image by Î²2 /2z with respect to the image formed from the field at the origin. Also the resolution cell size of the image has now changed from 2Ï/k sin Î¸x to 2Ï/k(sinÎ¸x +Î²/z). Thus, even if the illumination angle is zero, i.e., if sin Î¸x =0, detection of the electric field would still produce some image, the resolution of which is proportional to the angle subtended by the detector, Î²/z, to the object. This is related to the resolution for a lens of aperture Î². From Equation (23), the off center measurement of the electric field, while the angle of illumination is changed, does not perturb the measurement except to change the phase factor involved with the impulse response function.
Equation (22) is also applicable, if Î¸x =0, when any of the standard interferometric techniques to make incoherent holograms are used; and field at the point (Î²,0) is detected with respect to wavelength. In the case when a band of frequencies illuminates an object at the same time, the electric field at a point on the far-field region detected as a function of time is the image electric field given by Equation (8) since the time and frequency variables are Fourier transform variables with respect to each other.
Given for some function a(x,y), the operation g(x1,y1)=â«â«a(x,y)m(x,y;x1,y1)dxdy, the function a(xo,yo) may be retrieved from g(x1,y1) by using the operation â«â«g(x1,y1)m-1 (x,y,Î³x,Î³y)dx1 dy1 where the function m-1 (x,y;Î³x,Î³y) is defined by â«â«m(x,y;x1,y1)m-1 (x1,y1 ;Î³x,Î³y)dx1 dy1 =Î´(x-Î³x)Î´(y-Î³y). The function m in the situations described in the subresolution system corresponds to ei2Ïxx.sbsp.1 and m-1 to e-i2ÏÎ³.sbsp.xx.sbsp.1 where x1 is 1/Î» when wavelength variation is used for the imaging, sin Î¸x or sin Î¸y when angular variation is used. Alternately the object a(x,y) can be written as a matrix in which case m is a matrix and m-1 is an inverse matrix.
In the practical implementation of the theory involved in the analysis here, a coherent illumination tunable in wavelength or angular direction and a method for detecting the far field electrical field scattered by the object, such as by a heterodyne measurement, would be sufficient to provide the necessary information to produce a high resolution image of the object of interest. For optical wavelengths, an electro-optically tunable dye laser or a laser in combination with an acoustic-optic or electro-optic deflector may be used to produce rapid tuning of the wavelength and angle of illumination, while the electric field at point P may be detected by using a local oscillator to provide the coherent detection scheme.
The Fourier transform operation to reduce this signal to an image may be performed by a digital fast Fourier Transform Processor. An alternate technique would be to amplitude and phase modulate the output of a laser by an electro-optic cell with the signal and detect this, using heterodyne detection, with an integrating time longer than the signal duration. (The local oscillator may be a tunable laser.) The detector output obtained as a function of the frequency difference of the local oscillator and the signal laser would be the desired Fourier transform.
Equations (8), (10) and (17) are the results for the Fourier transform of the electric field, with respect to the angle or wavelength of illumination incident on some object at a point in the far field region of the object. They represent the image electric field of the object itself, the resolution of this image depending upon the angular and wavelength bandwidth through which the illumination can be tuned.
The foregoing discussion of the system of FIG. 1 in different modes has been generally in reference to the system without the optional lens L1, particularly in respect to the geometry of FIG. 2 and the discussion relation thereto which followed. For the corresponding geometry in the case of imaging with a lens, and a discussion of the present invention as it applied to that case, see a paper by the present inventor titled Sub-Resolution Imaging: Use of Wavelength and Angular Diversity Techniques published in Applied Physics Letters, Vol. 28, No. 8, at pages 451 to 453 (Apr. 15, 1976). That paper also illustrates the applicability of the invention to applications employing reflected wave field detection.
In summary, the Fourier transform of the wave field is obtained by a detector at a point on the image plane of an object as the angle, wavelength or distance from the object of the coherent wave source is varied to provide through an inverse Fourier transform calculated by a processor enhanced image data of the object which the resolution cell centered at the corresponding point on the object. Alternatively, only the intensity of the wave field may be detected as a Fourier spectrum at a point on the image plane, and the Fourier transform of the intensity is the autocorrelation of the transform of the wave field variation with wavelength. Thus, it is possible to use the output of the detector without heterodyne detection in order to obtain only intensity (wave amplitude) data for a Fourier spectrum of the image (i.e., the square of intensity of the Fourier transform that would otherwise be obtained by heterodyne detection), or to use the output of the detector with heterodyne detection to obtain both the amplitude and phase data of the image for a Fourier transform. This is so because the output of the heterodyne detector is the Fourier transform of the object at a point on the image plane, so that if the Fourier transform processor is not used, the result is a spatial Fourier transform of the object; and if the processor is used to obtain the inverse Fourier transform, a wave field image at a point on the image plane of an object is produced. Upon squaring that wave field image, an intensity image is produced for display, as on a cathode ray tube display unit. In other words, the squarer provides the square of intensity in the image wave field, and eliminates the phase data. Also a system without a processor may be of interest in some applications since the detector may provide the Fourier transform of the object if both modulation and heterodyne detection is used, as described hereinbefore, and the Fourier spectrum if only intensity detection is used, i.e., if elements 25, 31, 32 and 30 are omitted, as just noted. While the preferred embodiments described herein have been for the case of detecting radiation through the object, it is obvious that they can be modified for the case of reflection from the object. Consequently it is intended that the claims cover such modifications and variations.